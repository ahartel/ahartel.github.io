<!doctype html>
<meta charset="utf-8">
<link rel="stylesheet" href="../static/style.css">
<title>Blog â€” andreas.hartel.me</title>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<body>
  <header>
    <h1>andreas.hartel.me</h1>
    <nav>
      <ul class="nav navbar-nav">
        <li><a href="../">Welcome</a></li>
        
          <li class="active"><a href="./">Blog</a></li>
        
          <li><a href="../projects/">Projects</a></li>
        
          <li><a href="../about/">About</a></li>
        
      </ul>
    </nav>
  </header>
  <div class="page">
    
  
    
  <div class="blog-post">
  
    <h2><a href="creativity/">Creativity</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/deleted_handle">Andreas Hartel</a>
    
    on 2021-10-20
  </p>
  <p>I have written before <a href="/blog/making-a-mess-is-part-of-being-creative/">about creativity</a> and I've thought and read about it a bit recently.
There are 2 main things that I have recently discovered:
First, the idea that quantity leads to quality. I read <a href="https://austinkleon.com/2020/12/10/quantity-leads-to-quality-the-origin-of-a-parable/">this article</a> on Austin Kleon's blog (which I think I found via <a href="http://mattragland.com/">Matt Ragland</a>'s newsletter.
This idea is as simple as it is evident, the more you practice, the better you get.
But as trivial as it sounds, it is also non-trivial at the same time.
It becomes non-trivial when perfectionism comes into play, when you overthink things and stop doing things, when you become blocked.
This is illustrated nicely by the story of the ceramics teacher (mentioned in Austin Kleon's blog post) who divides a group of students into two, one which will be graded by quantity and one which will be graded by quality.
While the latter group tries too hard to produce their best work and therefore experiments too little, the quantity-based group experiments a lot and tries out a lot of things and produces ultimately the better work.
It is  this playful art of experimenting that makes a good artist/creator.</p>
<p>The second source of inspiration for me was <a href="https://www.youtube.com/watch?v=jZ4tOL8FB_g">this video on overcoming art block</a> by Valerie Lin.
She talks about her ways, her habits basically, that help her to keep experimenting and trying out new things, to overcome artist's block.
It starts by getting inspired by following the things that spark your interest or curiosity.
You continue by copying other people's work and therefore by practicing to use your tools and digest the inspiring material.
Ultimately, your brain will, often by some obscure subconscious process, produce some unique combination of the material you have digested before.
And that's what makes your work unique.
Once the basic idea has been unearthed, you may refine it again as you wish.</p>
<p>A similar process applies also to doing research, as was explained in the movie "The World of Thinking" by Nima Arkani-Hamed, about which <a href="/blog/the-world-of-thinking/">I wrote recently</a>.</p>

  </div>

  
    
  <div class="blog-post">
  
    <h2><a href="math-test/">Math test</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/deleted_handle">Andreas Hartel</a>
    
    on 2021-10-18
  </p>
  <p>When $a \ne 0$, there are two solutions to \(ax^2 + bx + c = 0\) and they are
$$x = {-b \pm \sqrt{b^2-4ac} \over 2a}.$$</p>

  </div>

  
    
  <div class="blog-post">
  
    <h2><a href="the-world-of-thinking/">The world of Thinking</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/deleted_handle">Andreas Hartel</a>
    
    on 2021-10-18
  </p>
  <p>Last week, I watched the documentary <a href="https://vimeo.com/ondemand/theworldofthinking">"The world of Thinking" on Vimeo.</a>
I chose to watch it because it portraits the <a href="https://en.wikipedia.org/wiki/Institute_for_Advanced_Study">Institute of Advanced Study</a> (IAS for short) which is a fascinating place to me.
It is located in Princeton, New Jersey, USA, and was the scientific home to many great and well-known mathematicians and theoretical physicists.
It does indeed harbor scientists of other disciplines as well but those are of less interest to me.
"The Institute", as it is often called, is a special place in that it is the closest implementation of the <a href="https://en.wikipedia.org/wiki/Ivory_tower">Ivory Tower</a> of Science.
The purpose of the Institute is to allow a few select scientists to focus as good as possible on expanding the boundaries of human knowledge.</p>
<p>What makes the movie "The world of Thinking" particularly interesting is that it portraits the institute, it's operating mode and 5 individuals that worked and lived there while the movie was shot.
These are <a href="https://en.m.wikipedia.org/wiki/Freeman_Dyson">Freeman Dyson</a>, Helmut Hofer, <a href="https://en.m.wikipedia.org/wiki/Vladimir_Voevodsky">Vladimir Voevodsky</a>, <a href="https://en.m.wikipedia.org/wiki/Nima_Arkani-Hamed">Nima Arkani-Hamed</a> and Yvonne Geyer.
It portraits nicely what motivates those people and it shows also that while they are completely free to chose the direction of their research and while they are completely freed from everyday chores and worries they still have their struggles which are then mostly psychological.</p>
<p>I must admit that the basic premise of the Institute sounds tempting at first.
Someone pays you money, provides you with an accommodation, food and an office.
You get in contact with the best scientists in the world in your field. If they don't already work next door then you can just invite them to work with you (at least that's how I imagine things to happen over there).</p>
<p>But then at a second glance, you might realise that the pressure that the people who work there put on themselves is huge.
Progress in research is an uncertain, non-deterministic process.
This is in the movie best illustrated with the example of Yvonne Geyer who, it seems, must just have finished her PhD before she came to the IAS.
She speeks openly about the pressure she feels when working at the IAS and when collaborating with her role models.</p>
<p>One of her role models is Nima Arkani-Hamed, a theoretical physicist who has been portrayed already by Quantamagazine and in the movie "Particle Fever".
In "The World of Thinking", he explains what drives him to work so hard, what his childhood has to do with his desire to do something great with his life and what it takes to be a great researcher.
He is also described as "never tired" and "always out there" by Yvonne Geyer, basically as someone who is always on the hunt for breakthroughs and never reluctant to discuss great physics with his colleagues.</p>
<p>The stories that moved me most were those of Vladimir Voevodsky and Helmut Hofer because both of them experienced seriously life changing events in their lives.
Vladimir Voevodsky apparently developed something like schizophrenia (at least that's what John Nash suffered from andn Voevodsky mentions having talked to Nash about his own experienced and having found similarities).
And while he was apparently able to live with this state of mind for a long time, the outro of the movie mentions that he had died 9 weeks after his last interview with the film crew.
I could not help but wonder if the psychological changes he experienced earlier in life were somehow correlates of an earlier physiological damage in his brain, but I will probably never know.</p>
<p>And then there was Helmut Hofers story.
This man worked for more than 15 years on his masterpiece mathematical theory and then lost his son during the year in which he finally wanted to finish his manuscript.
And it was clearly visible from the interviews what this experience had done to this man who was probably around 60 when the interviews for the movie were recorded.
Very sad to watch.</p>
<p>Overall, I really liked the movie and would certainly recommend it.
The footage of the Institute itself and the whole estate was great.
And then one other thing that I found particularly pleasing was that the historical anecdotes and life stories that were told by the interviewees have all been illustrated with some footage.
While this was never original footage, it was always chosen and edited in such a way that it did not distract from the voice the interviewee but it would always add a feeling to the whole story and help the viewer's imagination to travel back in time and live through the story together with its narrator.</p>

  </div>

  
    
  <div class="blog-post">
  
    <h2><a href="first-post/">Hello Website</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/deleted_handle">Andreas Hartel</a>
    
    on 2021-10-16
  </p>
  <p>If I could write a blog from scratch, what would I write about?
Why would I want to write a blog in the first place?
I have had a blog in one form or another for many years but I never got into a habit of contiually posting to on them.
The obvious answer to the question on what to write about is to write about the things that occupy my mind, that I find interesting or that move me.
I guess the only way to learn what I want to write about is to just write about something for a while.
Many people advocate this technique and I have tried it before but the attempt died of perfectionism.
I guess some of the articles that I have published in my last run were just too ambitious and took too much time to research and prepare.
This time I should try to write simpler and more frequent blog posts.</p>

  </div>

  
    
  <div class="blog-post">
  
    <h2><a href="reinforcement-learning-i-temporal-difference-learning/">Reinforcement learning I - Temporal difference learning</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/deleted_handle">Andreas Hartel</a>
    
    on 2017-07-17
  </p>
  <h2>Motivation</h2><p>After I've started working with reward-modulated STDP in spiking neural networks, I got curious about the background of research on which it was based. This led me to the book byÂ Richard SuttonÂ and Andrew BartoÂ calledÂ "Reinforcement Learning". Â The book is from 1998 and it's freely readable on the internet! In the book's Introduction they cover the example of an agent learning to beat a given (imperfect) agent in the game of Tic Tac Toe. Two remarks have to be made: 1. The agent has to be imperfect because a perfect agent in Tic Tac Toe (if it's the one doing the first move) can never be beaten. 2. The agent does not learn to play Tic Tac Toe, this skill is assumed, but it learns a value map for its policy.</p>
<p>Since I liked the example and wanted to try it out myself, I decided to write this blog post about it. By the way, the code can be found on github (run ttt_new.py).</p>
<h2>Introduction</h2><p>A few quotes taken fromÂ [Sutton &amp; Barto 2005]:</p>
<blockquote>Reinforcement learning is different from supervised learning, the kind of learning studied in most current research in machine learning, statistical pattern recognition, and artificial neural networks. Supervised learning is learning from examples provided by a knowledgable external supervisor.</blockquote><blockquote>Clearly, such an agent must be able to sense the state of the environment to some extent and must be able to take actions that affect the state. The agent also must have a goal or goals relating to the state of the environment. The formulation is intended to include just these three aspects--sensation, action, and goal--in their simplest possible forms without trivializing any of them.</blockquote><p><img src="/blog/reinforcement-learning-i-temporal-difference-learning/agent_environment_loop.png" class="center"></p>
<p class="center">Figure taken from [Sutton & Barto 2005]</p><blockquote>One of the challenges that arise in reinforcement learning and not in other kinds of learning is the trade-off between exploration and exploitation. To obtain a lot of reward, a reinforcement learning agent must prefer actions that it has tried in the past and found to be effective in producing reward. But to discover such actions, it has to try actions that it has not selected before. The agent has to exploit what it already knows in order to obtain reward, but it also has to explore in order to make better action selections in the future. The dilemma is that neither exploration nor exploitation can be pursued exclusively without failing at the task.</blockquote><h2>The 4 elements of reinforcement learning</h2><p>Quotes taken from [Sutton &amp; Barto 2005]</p>
<ul>
<li>Roughly speaking, <b>a policy</b> is a mapping from perceived states of the environment to actions to be taken when in those states. [...]Â  In some cases the policy may be a simple function or lookup table, whereas in others it may involve extensive computation such as a search process. The policy is the core of a reinforcement learning agent in the sense that it alone is sufficient to determine behavior. In general, policies may be stochastic.</li>

<li>A <b>reward function</b> defines the goal in a reinforcement learning problem. Roughly speaking, it maps each perceived state (or state-action pair) of the environment to a single number, a reward, indicating the intrinsic desirability of that state. A reinforcement learning agent's sole objective is to maximize the total reward it receives in the long run.</li>

<li>Whereas a reward function indicates what is good in an immediate sense, a <b>value function</b> specifies what is good in the long run. Roughly speaking, the value of a state is the total amount of reward an agent can expect to accumulate over the future, starting from that state. [...]
We seek actions that bring about states of highest value, not highest reward, because these actions obtain the greatest amount of reward for us over the long run. [...]
Rewards are basically given directly by the environment, but values must be estimated and reestimated from the sequences of observations an agent makes over its entire lifetime. In fact, the most important component of almost all reinforcement learning algorithms is a method for efficiently estimating values. The central role of value estimation is arguably the most important thing we have learned about reinforcement learning over the last few decades.</li>

<li>The fourth and final element of some reinforcement learning systems is a <b>model of the environment</b>. This is something that mimics the behavior of the environment. For example, given a state and action, the model might predict the resultant next state and next reward.</li>
</ul><h2>Learning a value function for Tic Tac Toe</h2><p>The learning process comprises N games. Each game consists of $K \geq 3$ turns. At the beginning of every game, the board gets reset to a state in which all nine fields are empty. Our agent plays Os and therefore plays the first turn in every game. At the beginning of the learning process the value map is initialized to 0.5 for every board state except for board states that show winning configurations for O, those have value 1.0, and board states that show draws or winning configurations for X, those have value 0.0.</p>
<p>Our agent can make two types of moves (actions): 1. Exploratory moves that ignore the value of the resulting board configuration and 2. Greedy moves that seek to maximize the value of the resulting board configuration. The probability of picking an exploratory move is $p_{ex}$.</p>
<p>After every greedy move, we update the value of the state $s$ before our opponents last move to become a bit closer to the value of the state $s'$ after our last move: $V(s) \leftarrow V(s) + \alpha [V(s') - V(s)]$. This is detailed in the following picture:</p>
<p><img src="/blog/reinforcement-learning-i-temporal-difference-learning/value_updates.png" class="center"></p>
<p class="center">Figure taken from [Sutton & Barto 2005]</p><p>The idea behind this update rule is to make the value of that would have resulted from our previous move closer to the value after our current move. This way, the value propagates back from the goal state along our chain of actions towards the start state.</p>
<p>According to [Sutton &amp; Barto 2005],</p>
<blockquote>This update rule is an example of a temporal-difference learning method, so called because its changes are based on a difference, $V(s') - V(s)$, between estimates at two different times.</blockquote><p>Each game is a series of board configurations. For greedy turns, the agent has to calculate all board configurations for all possible actions and pick the one with the highest value. Since the value map is initialized to 0.5 for all states except winning and losing ones and since there are 19,683 board states (naively counted) it makes sense to evaluate the value map lazily (although I must admit they I have not optimized my code and I have not verified this assumption).</p>
<h2>An implementation of TD learning for TTT</h2><p>I've implemented a version of this in Python. The code can be found on github (run ttt<em>new.py). This version chooses exploratory steps with a probability of $p</em>{ex}=0.01$.</p>
<p>The results of running the learning agent against a sub-optimal hard-coded oponent are shown in the following image. I ran 10,000 games in total and let the agent learn after each of its moves. The probability of it winning is shown in the picture for batches of 500 games. We can see that after approximately half the games it has learned how to beat the hard-coded agent about 80% of times.</p>
<p><img src="/blog/reinforcement-learning-i-temporal-difference-learning/success_over_time.png" class="center"></p>
<p class="center">Results of a training run. Fraction of wins of each agent and draws over training runs.</p><p><h2>Further questions</h2></p>
<ul>
<li>What is dynamic programming?</li>
<li>What are the combinatorics of TTT (c.f. Wikipedia article)</li>
</ul><p><h2>References</h2></p>
<ul>
<li>[Sutton & Barto 2005] http://incompleteideas.net/book/first/ebook/node10.html</li>
<li>My code on github: https://github.com/ahartel/reinforcement_learning</li>
</ul>
  </div>

  
    
  <div class="blog-post">
  
    <h2><a href="making-a-mess-is-part-of-being-creative/">Making a mess is part of being creative</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/deleted_handle">Andreas Hartel</a>
    
    on 2017-05-29
  </p>
  <p>Opposite to the Telegraph headline <a href="http://www.telegraph.co.uk/news/newstopics/howaboutthat/10225664/Having-a-messy-desk-makes-you-more-creative.html">Having a messy desk makes you 'more creative'</a>, a messy desk does probably not make you more creative, but creative people produce more mess. Or, in other words, making a mess is definitely a part of the creative process.</p>
<p>What do I mean by that: If you want to be creative you will first have to play around with the tools you have at hand. And during this process it is important to just try something without thinking too much about the ultimate goal. Part of the process is just to do something, see what happens and then start over, until eventually, you arrive at something you like.</p>
<p>The part of making a mess might involve writing down fragments of sentences onto a sheet of paper or typing it into a text editor. It might also involve drawing all sorts of funny ideas onto many sheets of paper, or even drawing the same thing over and over again while refining it in the process. Or, when writing software, it involves creating many different versions of the same software while refining the structure of the code.</p>
<p>Of course, at some point you might end up having to prepare a final version that you want to deploy. This is then the least pleasant part, it's the part when you need to file through all the ideas that you've produced and pick the gems out of the dusty ruins. At this point you need to be able to remember what you did and where you roughly did that.</p>
<p>I think <a href="https://www.christophniemann.com/">Christoph Niemann</a> summarized this process quite nicely in <a href="https://www.netflix.com/de-en/title/80057883">Abstract: The Art of Design</a>: You want to â€žbe a much more ruthless editor and at the same time be a much more careless artist.â€œ He also summarized this process nicely in <a href="http://www.newyorker.com/culture/culture-desk/the-story-of-my-app">this article for the New Yorker</a>.</p>
<p>Thus, you want to iterate between being a careless andÂ  almost child-like artist and on the other hand being a ruthless editor that drives the iterative process into the right direction.</p>

  </div>

  

  
  <div class="pagination">
    
      <span class="disabled">&laquo; Previous</span>
    
    | 1 |
    
      <span class="disabled">Next &raquo;</span>
    
  </div>


  </div>
  <footer>
  </footer>
</body>
